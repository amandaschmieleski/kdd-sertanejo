# ================================================================================
# REPROCESSAR ARQUIVO MASSIVO PARA ADICIONAR ANOS
# Atualiza o arquivo CSV massivo existente com informaÃ§Ãµes de ano
# ================================================================================

import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import random
import re
import json
from datetime import datetime

def fazer_request(url):
    """Faz uma requisiÃ§Ã£o HTTP e retorna o soup."""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        return BeautifulSoup(response.content, 'html.parser')
    except Exception as e:
        print(f"âŒ Erro ao acessar {url}: {str(e)}")
        return None

def extrair_ano_melhorado(soup):
    """Extrai o ano da mÃºsica usando estratÃ©gias melhoradas."""
    try:
        # 1. Procurar em JSON-LD (Schema.org) - estratÃ©gia mais confiÃ¡vel
        scripts_json = soup.find_all('script', type='application/ld+json')
        for script in scripts_json:
            try:
                data = json.loads(script.string)
                if isinstance(data, dict):
                    # Procurar datePublished, releaseDate, etc.
                    for campo in ['datePublished', 'releaseDate', 'dateCreated', 'uploadDate']:
                        if campo in data:
                            ano_match = re.search(r'\b(19|20)\d{2}\b', str(data[campo]))
                            if ano_match:
                                return int(ano_match.group())
                    
                    # Se for MusicRecording, procurar em album
                    if data.get('@type') == 'MusicRecording' and 'inAlbum' in data:
                        album = data['inAlbum']
                        if isinstance(album, dict) and 'datePublished' in album:
                            ano_match = re.search(r'\b(19|20)\d{2}\b', str(album['datePublished']))
                            if ano_match:
                                return int(ano_match.group())
                                
            except (json.JSONDecodeError, KeyError):
                continue
        
        # 2. Procurar em meta tags
        meta_tags = [
            ('property', 'music:release_date'),
            ('property', 'article:published_time'),
            ('name', 'publish_date'),
            ('name', 'release_date'),
            ('itemprop', 'datePublished'),
            ('itemprop', 'releaseDate')
        ]
        
        for attr, valor in meta_tags:
            meta = soup.find('meta', {attr: valor})
            if meta and meta.get('content'):
                ano_match = re.search(r'\b(19|20)\d{2}\b', meta.get('content'))
                if ano_match:
                    return int(ano_match.group())
        
        # 3. Procurar em elementos com microdata
        elementos_microdata = soup.find_all(attrs={'itemprop': re.compile(r'date|year', re.I)})
        for elem in elementos_microdata:
            texto = elem.get_text() or elem.get('content', '') or elem.get('datetime', '')
            ano_match = re.search(r'\b(19|20)\d{2}\b', texto)
            if ano_match:
                return int(ano_match.group())
        
        return None
        
    except Exception:
        return None

def reprocessar_arquivo_massivo():
    """Reprocessa o arquivo massivo para adicionar anos."""
    
    arquivo_original = "letras_sertanejo_massivo_20250930_192052.csv"
    
    print("ðŸ”„ REPROCESSAMENTO PARA ADICIONAR ANOS")
    print("=" * 70)
    print(f"ðŸ“ Arquivo original: {arquivo_original}")
    
    # Carregar dados existentes
    try:
        df = pd.read_csv(arquivo_original, encoding='utf-8')
        print(f"ðŸ“Š Carregadas {len(df)} mÃºsicas")
    except Exception as e:
        print(f"âŒ Erro ao carregar arquivo: {str(e)}")
        return
    
    # Verificar estrutura
    print(f"ðŸ“‹ Colunas: {list(df.columns)}")
    
    # Contar mÃºsicas sem ano
    sem_ano = df['ano'].isna().sum()
    com_ano = len(df) - sem_ano
    
    print(f"ðŸ“… MÃºsicas com ano: {com_ano}")
    print(f"â“ MÃºsicas sem ano: {sem_ano}")
    
    if sem_ano == 0:
        print("âœ… Todas as mÃºsicas jÃ¡ tÃªm ano!")
        return
    
    print(f"\nâ³ Processando {sem_ano} mÃºsicas sem ano...")
    print("âš ï¸  ATENÃ‡ÃƒO: Este processo pode demorar bastante!")
    print("â±ï¸  Estimativa: ~3 segundos por mÃºsica")
    print(f"â±ï¸  Tempo estimado total: ~{(sem_ano * 3) // 60} minutos")
    
    resposta = input("\nâ“ Continuar? (s/n): ").lower().strip()
    if resposta != 's':
        print("âŒ OperaÃ§Ã£o cancelada")
        return
    
    print("\nðŸš€ Iniciando reprocessamento...")
    
    # Processar mÃºsicas sem ano
    sucessos = 0
    falhas = 0
    
    for i, row in df.iterrows():
        if pd.isna(row['ano']) or row['ano'] == '':
            # Tentar extrair ano
            url = row['url']
            titulo = row['titulo']
            artista = row['artista']
            
            print(f"[{i+1}/{len(df)}] ðŸŽµ {artista} - {titulo}")
            
            # Fazer requisiÃ§Ã£o
            soup = fazer_request(url)
            if soup:
                ano = extrair_ano_melhorado(soup)
                if ano:
                    df.at[i, 'ano'] = ano
                    sucessos += 1
                    print(f"   âœ… Ano encontrado: {ano}")
                else:
                    falhas += 1
                    print(f"   âŒ Ano nÃ£o encontrado")
            else:
                falhas += 1
                print(f"   âŒ Erro ao acessar pÃ¡gina")
            
            # Delay para nÃ£o sobrecarregar o servidor
            time.sleep(random.uniform(2, 4))
            
            # Mostrar progresso a cada 10 mÃºsicas
            if (i + 1) % 10 == 0:
                porcentagem = ((i + 1) / len(df)) * 100
                print(f"\nðŸ“Š Progresso: {porcentagem:.1f}% - Sucessos: {sucessos}, Falhas: {falhas}")
    
    # Resultados finais
    print("\n" + "=" * 70)
    print("ðŸ“Š RESULTADOS DO REPROCESSAMENTO:")
    print(f"   âœ… Anos adicionados: {sucessos}")
    print(f"   âŒ Falhas: {falhas}")
    
    # EstatÃ­sticas finais
    total_com_ano = df['ano'].notna().sum()
    porcentagem_final = (total_com_ano / len(df)) * 100
    print(f"   ðŸ“… Total de mÃºsicas com ano: {total_com_ano}/{len(df)} ({porcentagem_final:.1f}%)")
    
    # Salvar arquivo atualizado
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    arquivo_atualizado = f"letras_sertanejo_com_anos_{timestamp}.csv"
    
    try:
        df.to_csv(arquivo_atualizado, index=False, encoding='utf-8')
        print(f"ðŸ’¾ Arquivo salvo: {arquivo_atualizado}")
        
        # TambÃ©m salvar em JSON
        arquivo_json = arquivo_atualizado.replace('.csv', '.json')
        df.to_json(arquivo_json, orient='records', indent=2, force_ascii=False)
        print(f"ðŸ’¾ Arquivo JSON salvo: {arquivo_json}")
        
    except Exception as e:
        print(f"âŒ Erro ao salvar: {str(e)}")
    
    # DistribuiÃ§Ã£o de anos
    if total_com_ano > 0:
        print("\nðŸ“Š DISTRIBUIÃ‡ÃƒO DE ANOS:")
        distribuicao = df['ano'].value_counts().sort_index()
        for ano, count in distribuicao.items():
            if pd.notna(ano):
                print(f"   {int(ano)}: {count} mÃºsicas")

if __name__ == "__main__":
    reprocessar_arquivo_massivo()
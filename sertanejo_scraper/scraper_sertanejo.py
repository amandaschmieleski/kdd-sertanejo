# ================================================================================
# SCRAPER SEQUENCIAL DE LETRAS DE SERTANEJO
# Web scraping do site Letras.mus.br para coleta de letras de m√∫sica sertaneja
# Data: 30/09/2025
# ================================================================================

# Bibliotecas necess√°rias (instalar com: pip install requests beautifulsoup4 pandas unidecode)
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
import re
import json
from datetime import datetime
from urllib.parse import urljoin, quote

# Tentar importar unidecode, se n√£o estiver dispon√≠vel usar alternativa
try:
    import unidecode
    HAS_UNIDECODE = True
except ImportError:
    HAS_UNIDECODE = False
    print("‚ö†Ô∏è  Biblioteca 'unidecode' n√£o encontrada. Instale com: pip install unidecode")
    print("   Continuando sem remo√ß√£o de acentos...")

def remover_acentos(texto):
    """Remove acentos do texto, com ou sem unidecode."""
    if HAS_UNIDECODE:
        return unidecode.unidecode(texto)
    else:
        # Alternativa simples sem unidecode
        replacements = {
            '√°': 'a', '√†': 'a', '√£': 'a', '√¢': 'a', '√§': 'a',
            '√©': 'e', '√®': 'e', '√™': 'e', '√´': 'e',
            '√≠': 'i', '√¨': 'i', '√Æ': 'i', '√Ø': 'i',
            '√≥': 'o', '√≤': 'o', '√µ': 'o', '√¥': 'o', '√∂': 'o',
            '√∫': 'u', '√π': 'u', '√ª': 'u', '√º': 'u',
            '√ß': 'c', '√±': 'n',
            '√Å': 'A', '√Ä': 'A', '√É': 'A', '√Ç': 'A', '√Ñ': 'A',
            '√â': 'E', '√à': 'E', '√ä': 'E', '√ã': 'E',
            '√ç': 'I', '√å': 'I', '√é': 'I', '√è': 'I',
            '√ì': 'O', '√í': 'O', '√ï': 'O', '√î': 'O', '√ñ': 'O',
            '√ö': 'U', '√ô': 'U', '√õ': 'U', '√ú': 'U',
            '√á': 'C', '√ë': 'N'
        }
        for accented, normal in replacements.items():
            texto = texto.replace(accented, normal)
        return texto

# ================================================================================
# CONFIGURA√á√ïES GLOBAIS
# ================================================================================

# Configura√ß√µes do scraper
BASE_URL = "https://www.letras.mus.br"
DELAY_MIN = 1.0  # Delay m√≠nimo entre requests (segundos)
DELAY_MAX = 3.0  # Delay m√°ximo entre requests (segundos)
TIMEOUT = 30     # Timeout para requests (segundos)

# Headers para parecer mais humano
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
    'Accept-Encoding': 'gzip, deflate',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
}

# Lista de artistas populares de sertanejo
ARTISTAS_POPULARES = [
    "Zez√© Di Camargo e Luciano",
    "Chit√£ozinho e Xoror√≥",
    "Bruno e Marrone",
    "Victor e Leo",
    "Jorge e Mateus",
    "Henrique e Juliano",
    "Mar√≠lia Mendon√ßa",
    "Gusttavo Lima",
    "Luan Santana",
    "Wesley Safad√£o",
    "Matheus e Kauan",
    "Simone e Simaria",
    "Maiara e Maraisa",
    "Z√© Neto e Cristiano",
    "Israel e Rodolffo",
    "C√©sar Menotti e Fabiano",
    "Jo√£o Bosco e Vin√≠cius",
    "Marcos e Belutti",
    "Thaeme e Thiago",
    "Fernando e Sorocaba"
]

print("=" * 80)
print("SCRAPER SEQUENCIAL DE LETRAS DE SERTANEJO")
print("=" * 80)
print(f"Iniciado em: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
print()

# ================================================================================
# FUN√á√ïES AUXILIARES
# ================================================================================

def aplicar_delay():
    """Aplica delay aleat√≥rio entre requests."""
    delay = random.uniform(DELAY_MIN, DELAY_MAX)
    time.sleep(delay)

def fazer_request(url):
    """
    Faz request HTTP com tratamento de erros.
    Retorna BeautifulSoup object ou None se erro.
    """
    try:
        aplicar_delay()
        response = requests.get(url, headers=HEADERS, timeout=TIMEOUT)
        response.raise_for_status()
        
        # Verificar se n√£o √© p√°gina de erro
        if "p√°gina n√£o encontrada" in response.text.lower():
            print(f"‚ö†Ô∏è  P√°gina n√£o encontrada: {url}")
            return None
        
        soup = BeautifulSoup(response.content, 'html.parser')
        return soup
        
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Erro ao acessar {url}: {str(e)}")
        return None

def normalizar_nome_artista(nome_artista):
    """Normaliza o nome do artista para URL."""
    # Remover acentos
    nome_normalizado = remover_acentos(nome_artista.lower())
    # Substituir espa√ßos e caracteres especiais
    nome_normalizado = nome_normalizado.replace(' ', '-').replace('&', 'e')
    # Remover caracteres n√£o alfanum√©ricos (exceto h√≠fen)
    nome_normalizado = re.sub(r'[^a-z0-9\-]', '', nome_normalizado)
    return nome_normalizado

def limpar_letra(texto_bruto):
    """Limpa e formata o texto da letra."""
    if not texto_bruto:
        return ""
    
    # Remover quebras de linha excessivas
    linhas = [linha.strip() for linha in texto_bruto.split('\n')]
    linhas = [linha for linha in linhas if linha]  # Remover linhas vazias
    
    # Juntar linhas com espa√ßos para evitar palavras concatenadas
    texto_limpo = ' '.join(linhas)
    
    # Corrigir concatena√ß√µes comuns onde quebras de linha juntaram palavras
    import re
    
    # Padr√£o: palavra(min√∫scula)MAI√öSCULA -> palavra MAI√öSCULA  
    texto_limpo = re.sub(r'([a-z√°√©√≠√≥√∫√¢√™√Æ√¥√ª√†√®√¨√≤√π√£√ß])([√Å√â√ç√ì√ö√Ç√ä√é√î√õ√Ä√à√å√í√ô√É√áA-Z])', r'\1 \2', texto_limpo)
    
    # Padr√£o: pontua√ß√£o+MAI√öSCULA -> pontua√ß√£o MAI√öSCULA
    texto_limpo = re.sub(r'([!?.,;:])([A-Z√Å√â√ç√ì√ö√Ç√ä√é√î√õ√Ä√à√å√í√ô√É√á])', r'\1 \2', texto_limpo)
    
    # Remover caracteres especiais desnecess√°rios
    texto_limpo = texto_limpo.replace('\r', '')
    texto_limpo = texto_limpo.replace('\t', ' ')
    
    # Remover espa√ßos duplos
    while '  ' in texto_limpo:
        texto_limpo = texto_limpo.replace('  ', ' ')
    
    return texto_limpo.strip()

def extrair_ano(soup):
    """Extrai o ano da m√∫sica se dispon√≠vel."""
    try:
        import json
        
        # 1. Procurar em JSON-LD (Schema.org) - estrat√©gia mais confi√°vel
        scripts_json = soup.find_all('script', type='application/ld+json')
        for script in scripts_json:
            try:
                data = json.loads(script.string)
                if isinstance(data, dict):
                    # Procurar datePublished, releaseDate, etc.
                    for campo in ['datePublished', 'releaseDate', 'dateCreated', 'uploadDate']:
                        if campo in data:
                            ano_match = re.search(r'\b(19|20)\d{2}\b', str(data[campo]))
                            if ano_match:
                                return int(ano_match.group())
                    
                    # Se for MusicRecording, procurar em album
                    if data.get('@type') == 'MusicRecording' and 'inAlbum' in data:
                        album = data['inAlbum']
                        if isinstance(album, dict) and 'datePublished' in album:
                            ano_match = re.search(r'\b(19|20)\d{2}\b', str(album['datePublished']))
                            if ano_match:
                                return int(ano_match.group())
                                
            except (json.JSONDecodeError, KeyError):
                continue
        
        # 2. Procurar em meta tags
        meta_tags = [
            ('property', 'music:release_date'),
            ('property', 'article:published_time'),
            ('name', 'publish_date'),
            ('name', 'release_date'),
            ('itemprop', 'datePublished'),
            ('itemprop', 'releaseDate')
        ]
        
        for attr, valor in meta_tags:
            meta = soup.find('meta', {attr: valor})
            if meta and meta.get('content'):
                ano_match = re.search(r'\b(19|20)\d{2}\b', meta.get('content'))
                if ano_match:
                    return int(ano_match.group())
        
        # 3. Procurar em elementos com microdata
        elementos_microdata = soup.find_all(attrs={'itemprop': re.compile(r'date|year', re.I)})
        for elem in elementos_microdata:
            texto = elem.get_text() or elem.get('content', '') or elem.get('datetime', '')
            ano_match = re.search(r'\b(19|20)\d{2}\b', texto)
            if ano_match:
                return int(ano_match.group())
        
        # 4. Estrat√©gia original como fallback
        elementos_ano = [
            soup.find('span', class_='year'),
            soup.find('time'),
            soup.find('div', class_='song-info')
        ]
        
        for elemento in elementos_ano:
            if elemento:
                texto = elemento.get_text()
                match_ano = re.search(r'\b(19|20)\d{2}\b', texto)
                if match_ano:
                    return int(match_ano.group())
        
        return None
        
    except Exception:
        return None

def validar_qualidade_letra(dados_musica):
    """
    Valida a qualidade de uma letra.
    Retorna True se a letra tem qualidade adequada.
    """
    letra = dados_musica.get('letra', '')
    titulo = dados_musica.get('titulo', '')
    
    # DEBUG: mostrar info da letra
    print(f"   üìù Validando: {len(letra)} caracteres, {len(letra.split())} palavras")
    
    # Verificar comprimento m√≠nimo
    contagem_palavras = len(letra.split())
    if contagem_palavras < 10:
        print(f"   ‚ùå Muito curta: {contagem_palavras} palavras")
        return False
    
    # Verificar se n√£o √© muito longa (poss√≠vel erro)
    if contagem_palavras > 2000:
        print(f"   ‚ùå Muito longa: {contagem_palavras} palavras")
        return False
    
    # Verificar indicadores de conte√∫do inv√°lido
    indicadores_invalidos = [
        'p√°gina n√£o encontrada',
        'erro 404',
        'acesso negado',
        'letra n√£o dispon√≠vel'
    ]
    
    letra_lower = letra.lower()
    titulo_lower = titulo.lower()
    
    for indicador in indicadores_invalidos:
        if indicador in letra_lower or indicador in titulo_lower:
            print(f"   ‚ùå Conte√∫do inv√°lido: {indicador}")
            return False
    
    print(f"   ‚úÖ Qualidade OK: {contagem_palavras} palavras")
    return True

# ================================================================================
# FUN√á√ÉO PRINCIPAL DE BUSCA DE ARTISTA
# ================================================================================

def buscar_artista(nome_artista):
    """
    Busca o URL do artista no site.
    Retorna URL do artista ou None se n√£o encontrado.
    """
    print(f"üîç Buscando artista: {nome_artista}")
    
    # Tentar URL direta primeiro
    nome_normalizado = normalizar_nome_artista(nome_artista)
    url_direta = f"{BASE_URL}/{nome_normalizado}/"
    
    soup = fazer_request(url_direta)
    
    # Verificar se √© p√°gina v√°lida de artista
    if soup and (soup.find('h1', class_='head_title') or 
                soup.find('div', class_='artist-info') or 
                soup.find('ul', class_='songList') or
                soup.find('h1') and 'discografia' in soup.get_text().lower()):
        print(f"‚úÖ Artista encontrado: {url_direta}")
        return url_direta
    
    # Se URL direta n√£o funcionou, tentar busca
    print(f"üîç Tentando busca por: {nome_artista}")
    url_busca = f"{BASE_URL}/busca.php?words={quote(nome_artista)}"
    soup = fazer_request(url_busca)
    
    if not soup:
        return None
    
    # Procurar link do artista nos resultados
    links_artista = soup.find_all('a', href=True)
    for link in links_artista:
        href = link.get('href', '')
        texto = link.get_text(strip=True)
        
        if (href.startswith('/') and 
            nome_artista.lower() in texto.lower() and
            'discografia' in href):
            
            url_artista = urljoin(BASE_URL, href.replace('/discografia', ''))
            print(f"‚úÖ Artista encontrado via busca: {url_artista}")
            return url_artista
    
    print(f"‚ùå Artista n√£o encontrado: {nome_artista}")
    return None

# ================================================================================
# FUN√á√ÉO PARA OBTER LISTA DE M√öSICAS
# ================================================================================

def obter_musicas_artista(url_artista, limite=None):
    """
    Obt√©m lista de m√∫sicas do artista.
    Retorna lista de dicion√°rios com informa√ß√µes das m√∫sicas.
    """
    print(f"üìã Obtendo lista de m√∫sicas de: {url_artista}")
    
    soup = fazer_request(url_artista)
    if not soup:
        return []
    
    musicas = []
    
    # Procurar diferentes estruturas de lista de m√∫sicas
    containers_musicas = [
        soup.find_all('li', class_='songList-table-row'),
        soup.find_all('a', class_='song-name'),
        soup.find_all('div', class_='cnt-list-songs'),
    ]
    
    for lista_container in containers_musicas:
        if lista_container:
            for item in lista_container:
                # Extrair link da m√∫sica
                link = item.find('a', href=True)
                if not link:
                    if item.name == 'a':
                        link = item
                    else:
                        continue
                
                titulo_musica = link.get_text(strip=True)
                url_musica = urljoin(BASE_URL, link['href'])
                
                if titulo_musica and url_musica:
                    musicas.append({
                        'titulo': titulo_musica,
                        'url': url_musica,
                        'url_artista': url_artista
                    })
                    
                    if limite and len(musicas) >= limite:
                        break
            break
    
    print(f"üìã Encontradas {len(musicas)} m√∫sicas")
    return musicas[:limite] if limite else musicas

# ================================================================================
# FUN√á√ÉO PARA EXTRAIR LETRA DE UMA M√öSICA
# ================================================================================

def extrair_letra_musica(url_musica, nome_artista_real=None):
    """
    Extrai a letra de uma m√∫sica.
    Retorna dicion√°rio com dados da m√∫sica ou None.
    """
    soup = fazer_request(url_musica)
    if not soup:
        return None
    
    try:
        # Extrair t√≠tulo
        elemento_titulo = soup.find('h1', class_='head_title')
        if not elemento_titulo:
            elemento_titulo = soup.find('h1')
        
        titulo = elemento_titulo.get_text(strip=True) if elemento_titulo else "T√≠tulo n√£o encontrado"
        
        # Usar nome do artista fornecido ou tentar extrair da p√°gina
        if nome_artista_real:
            artista = nome_artista_real
        else:
            # Extrair artista da p√°gina (fallback)
            elemento_artista = soup.find('h2', class_='head_subtitle')
            if not elemento_artista:
                elemento_artista = soup.find('h2')
            artista = elemento_artista.get_text(strip=True) if elemento_artista else "Artista n√£o encontrado"
        
        # Extrair letra - tentar diferentes seletores
        seletores_letra = [
            '.lyric-original',      # Principal do Letras.mus.br
            'div[class*="lyric"]',
            'div[class*="letra"]',
            'div.cnt-lyric',
            'pre.lyric'
        ]
        
        elemento_letra = None
        for seletor in seletores_letra:
            elemento_letra = soup.select_one(seletor)
            if elemento_letra and len(elemento_letra.get_text().strip()) > 50:
                break
        
        if not elemento_letra:
            print(f"‚ö†Ô∏è  Letra n√£o encontrada em: {url_musica}")
            return None
        
        # Limpar e extrair texto da letra
        texto_letra = limpar_letra(elemento_letra.get_text())
        
        if not texto_letra.strip():
            print(f"‚ö†Ô∏è  Letra vazia em: {url_musica}")
            return None
        
        # Extrair ano se dispon√≠vel
        ano = extrair_ano(soup)
        
        # Montar dados da m√∫sica
        dados_musica = {
            'titulo': titulo,
            'artista': artista,
            'letra': texto_letra,
            'url': url_musica,
            'ano': ano,
            'coletado_em': datetime.now().isoformat(),
            'contagem_palavras': len(texto_letra.split()),
            'contagem_linhas': len(texto_letra.split('\n'))
        }
        
        # Validar qualidade
        if validar_qualidade_letra(dados_musica):
            print(f"‚úÖ Letra extra√≠da: {artista} - {titulo} ({dados_musica['contagem_palavras']} palavras)")
            return dados_musica
        else:
            print(f"‚ö†Ô∏è  Letra de baixa qualidade rejeitada: {titulo}")
            return None
        
    except Exception as e:
        print(f"‚ùå Erro ao extrair letra de {url_musica}: {str(e)}")
        return None

# ================================================================================
# FUN√á√ÉO PRINCIPAL DE SCRAPING
# ================================================================================

def fazer_scraping_artista(nome_artista, max_musicas=None):
    """
    Faz scraping completo de um artista.
    Retorna lista de dicion√°rios com letras das m√∫sicas.
    """
    print(f"\nüéµ Iniciando scraping de: {nome_artista}")
    print("-" * 60)
    
    # 1. Buscar artista
    url_artista = buscar_artista(nome_artista)
    if not url_artista:
        print(f"‚ùå Artista n√£o encontrado: {nome_artista}")
        return []
    
    # 2. Obter lista de m√∫sicas
    musicas = obter_musicas_artista(url_artista, limite=max_musicas)
    if not musicas:
        print(f"‚ùå Nenhuma m√∫sica encontrada para: {nome_artista}")
        return []
    
    print(f"üéº Iniciando download de {len(musicas)} m√∫sicas...")
    
    # 3. Baixar letras
    letras_coletadas = []
    contador_sucesso = 0
    contador_falha = 0
    
    for i, musica in enumerate(musicas, 1):
        print(f"[{i}/{len(musicas)}] Processando: {musica['titulo']}")
        
        letra = extrair_letra_musica(musica['url'], nome_artista)
        if letra:
            letras_coletadas.append(letra)
            contador_sucesso += 1
        else:
            contador_falha += 1
        
        # Rate limiting mais agressivo para muitas m√∫sicas
        if len(musicas) > 20:
            time.sleep(random.uniform(2.0, 4.0))
    
    print(f"\nüìä Scraping de {nome_artista} conclu√≠do:")
    print(f"   ‚úÖ Sucessos: {contador_sucesso}")
    print(f"   ‚ùå Falhas: {contador_falha}")
    if (contador_sucesso + contador_falha) > 0:
        taxa_sucesso = (contador_sucesso/(contador_sucesso+contador_falha)*100)
        print(f"   üìà Taxa de sucesso: {taxa_sucesso:.1f}%")
    
    # Mostrar preview das m√∫sicas coletadas
    if letras_coletadas:
        print(f"\nüéµ M√öSICAS COLETADAS DE {nome_artista.upper()}:")
        print("-" * 70)
        for i, musica in enumerate(letras_coletadas, 1):
            titulo_truncado = musica['titulo'][:40] + "..." if len(musica['titulo']) > 40 else musica['titulo']
            print(f"   {i:2d}. {titulo_truncado:<43} ({musica['contagem_palavras']:3d} palavras)")
        print("-" * 70)
    
    return letras_coletadas

# ================================================================================
# FUN√á√ÉO PARA SALVAR DADOS
# ================================================================================

def salvar_dados(dados_letras, nome_arquivo_base):
    """Salva os dados coletados em diferentes formatos."""
    if not dados_letras:
        print("‚ö†Ô∏è  Nenhum dado para salvar")
        return
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Salvar em JSON
    arquivo_json = f"{nome_arquivo_base}_{timestamp}.json"
    with open(arquivo_json, 'w', encoding='utf-8') as f:
        json.dump(dados_letras, f, ensure_ascii=False, indent=2)
    print(f"üíæ Dados salvos em JSON: {arquivo_json}")
    
    # Salvar em CSV
    try:
        df = pd.DataFrame(dados_letras)
        arquivo_csv = f"{nome_arquivo_base}_{timestamp}.csv"
        df.to_csv(arquivo_csv, index=False, encoding='utf-8')
        print(f"üíæ Dados salvos em CSV: {arquivo_csv}")
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao salvar CSV: {str(e)}")

def gerar_relatorio(dados_letras):
    """Gera relat√≥rio estat√≠stico dos dados coletados."""
    if not dados_letras:
        print("‚ö†Ô∏è  Nenhum dado para relat√≥rio")
        return
    
    print("\n" + "=" * 80)
    print("üìä RELAT√ìRIO ESTAT√çSTICO - LETRAS DE SERTANEJO")
    print("=" * 80)
    
    # Criar DataFrame para an√°lise
    df = pd.DataFrame(dados_letras)
    
    total_musicas = len(dados_letras)
    total_palavras = sum(musica['contagem_palavras'] for musica in dados_letras)
    media_palavras = total_palavras / total_musicas if total_musicas > 0 else 0
    
    # Estat√≠sticas gerais
    print(f"\nüìà ESTAT√çSTICAS GERAIS:")
    print(f"   Total de m√∫sicas coletadas: {total_musicas}")
    print(f"   Total de palavras: {total_palavras:,}")
    print(f"   M√©dia de palavras por m√∫sica: {media_palavras:.1f}")
    print(f"   Artistas √∫nicos: {df['artista'].nunique()}")
    
    # Tabela resumo por artista
    print(f"\nüé§ RESUMO POR ARTISTA:")
    resumo_artista = df.groupby('artista').agg({
        'titulo': 'count',
        'contagem_palavras': ['sum', 'mean'],
        'contagem_linhas': 'mean',
        'ano': lambda x: f"{x.min()}-{x.max()}" if x.notna().any() else "N/A"
    }).round(1)
    
    # Simplificar nomes das colunas
    resumo_artista.columns = ['M√∫sicas', 'Total Palavras', 'M√©dia Palavras', 'M√©dia Linhas', 'Per√≠odo']
    
    # Exibir tabela formatada
    print(resumo_artista.to_string())
    
    # Top 10 m√∫sicas com mais palavras
    print(f"\nüèÜ TOP 10 M√öSICAS COM MAIS PALAVRAS:")
    top_musicas = df.nlargest(10, 'contagem_palavras')[['artista', 'titulo', 'contagem_palavras']]
    top_musicas.columns = ['Artista', 'M√∫sica', 'Palavras']
    print(top_musicas.to_string(index=False))
    
    # Distribui√ß√£o de anos (se dispon√≠vel)
    anos_com_dados = df[df['ano'].notna()]
    if len(anos_com_dados) > 0:
        print(f"\nüìÖ DISTRIBUI√á√ÉO POR D√âCADA:")
        anos_com_dados['decada'] = (anos_com_dados['ano'] // 10) * 10
        dist_decada = anos_com_dados['decada'].value_counts().sort_index()
        
        for decada, count in dist_decada.items():
            print(f"   {int(decada)}s: {count} m√∫sicas")
    
    # Estat√≠sticas de qualidade
    print(f"\nüîç ESTAT√çSTICAS DE QUALIDADE:")
    print(f"   Menor n√∫mero de palavras: {df['contagem_palavras'].min()}")
    print(f"   Maior n√∫mero de palavras: {df['contagem_palavras'].max()}")
    print(f"   Desvio padr√£o de palavras: {df['contagem_palavras'].std():.1f}")
    
    quartis = df['contagem_palavras'].quantile([0.25, 0.5, 0.75])
    print(f"   Q1 (25%): {quartis[0.25]:.0f} palavras")
    print(f"   Mediana: {quartis[0.5]:.0f} palavras") 
    print(f"   Q3 (75%): {quartis[0.75]:.0f} palavras")
    
    print("\n" + "=" * 80)

# ================================================================================
# EXECU√á√ÉO PRINCIPAL
# ================================================================================

def main():
    """Fun√ß√£o principal do programa."""
    
    # Configura√ß√µes do usu√°rio - COLETA MASSIVA PARA MODELO ML
    ARTISTAS_PARA_COLETAR = [
        # ============ J√Å COLETADOS (manter) ============
        "Chit√£ozinho e Xoror√≥",
        "Bruno e Marrone", 
        "Henrique & Juliano",
        "Jorge & Mateus",
        "Zez√© Di Camargo & Luciano",
        "Leandro & Leonardo",
        "Mar√≠lia Mendon√ßa",
        "Paula Fernandes",
        "Milion√°rio e Jos√© Rico",
        "Almir Sater",
        "Diego e Victor Hugo",
        "Gustavo Mioto",
        
        # ============ EXPANS√ÉO MASSIVA ============
        # Sertanejo Moderno Top
        "Luan Santana",
        "Gusttavo Lima", 
        "Z√© Neto e Cristiano",
        "Matheus & Kauan",
        
        # Feminino
        "Simone Mendes",
        "Ana Castela",
        "Lauana Prado",
        "Maiara & Maraisa",
        
        # Cl√°ssicos/Ic√¥nicos
        "Rick & Renner",
        "Victor & Leo",
        "Daniel",
        "Leonardo",
        "Chrystian & Ralf",
        
        # Nova Gera√ß√£o
        "Felipe Ara√∫jo",
        "Murilo Huff",
        "Z√© Felipe",
        "Luan Pereira",
        
        # Raiz/Tradicional
        "Ti√£o Carreiro e Pardinho",
        "Trio Parada Dura",
        "Jo√£o Mineiro e Marciano",
        "Gino e Geno",
        "S√©rgio Reis",
        "Tonico e Tinoco",
        "Teodoro e Sampaio",
        
        # Populares Diversos
        "Eduardo Costa",
        "Hugo & Guilherme",
        "Clayton e Rom√°rio",
        "Guilherme & Benuto",
        "Matogrosso & Mathias",
        "√çcaro e Gilmar",
        "Gian e Giovani",
        "Rionegro & Solim√µes",
        "Jo√£o Paulo e Daniel",
        "Marcos & Belutti",
        "Louren√ßo e Lourival",
        "Edson & Hudson",
        "Chico Rey e Paran√°",
        "Guilherme & Santiago"
    ]
    
    MAX_MUSICAS_POR_ARTISTA = 10  # Reduzindo para 10 para cobrir mais artistas
    NOME_ARQUIVO_BASE = "letras_sertanejo_massivo"
    
    print("üöÄ Configura√ß√µes:")
    print(f"   Artistas: {', '.join(ARTISTAS_PARA_COLETAR)}")
    print(f"   M√°x. m√∫sicas por artista: {MAX_MUSICAS_POR_ARTISTA or 'Todas'}")
    print(f"   Delay entre requests: {DELAY_MIN}-{DELAY_MAX}s")
    print()
    
    # Coletar dados de todos os artistas
    todas_as_letras = []
    
    for artista in ARTISTAS_PARA_COLETAR:
        letras_artista = fazer_scraping_artista(artista, MAX_MUSICAS_POR_ARTISTA)
        todas_as_letras.extend(letras_artista)
        
        # Pequena pausa entre artistas
        if len(ARTISTAS_PARA_COLETAR) > 1:
            print("‚è≥ Pausa entre artistas...")
            time.sleep(5)
    
    # Salvar dados coletados
    print("\n" + "=" * 60)
    print("üíæ SALVANDO DADOS")
    print("=" * 60)
    
    salvar_dados(todas_as_letras, NOME_ARQUIVO_BASE)
    
    # Gerar relat√≥rio
    gerar_relatorio(todas_as_letras)
    
    print("\n" + "=" * 60)
    print("‚úÖ SCRAPING CONCLU√çDO COM SUCESSO!")
    print("=" * 60)
    print(f"Finalizado em: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")

# ================================================================================
# PONTO DE ENTRADA
# ================================================================================

if __name__ == "__main__":
    main()

# ================================================================================
# INSTRU√á√ïES DE USO:
# ================================================================================
"""
COMO USAR ESTE SCRAPER:

1. INSTALA√á√ÉO:
   pip install requests beautifulsoup4 pandas

2. CONFIGURA√á√ÉO:
   - Edite a lista ARTISTAS_PARA_COLETAR na fun√ß√£o main()
   - Ajuste MAX_MUSICAS_POR_ARTISTA conforme necess√°rio
   - Modifique DELAY_MIN/DELAY_MAX se necess√°rio

3. EXECU√á√ÉO:
   python scraper_sertanejo.py

4. RESULTADOS:
   - Arquivos JSON e CSV ser√£o criados automaticamente
   - Relat√≥rio estat√≠stico ser√° exibido no final
   - Logs de progresso mostram o andamento

EXEMPLO DE CONFIGURA√á√ÉO:

ARTISTAS_PARA_COLETAR = [
    "Zez√© Di Camargo e Luciano",
    "Chit√£ozinho e Xoror√≥",
    "Henrique e Juliano"
]

MAX_MUSICAS_POR_ARTISTA = 50  # ou None para todas

OBSERVA√á√ïES:
- O script respeita rate limiting (1-3s entre requests)
- M√∫sicas de baixa qualidade s√£o automaticamente filtradas
- Dados s√£o salvos em JSON e CSV com timestamp
- O c√≥digo √© totalmente sequencial, sem classes
"""